\documentclass[8pt]{beamer}

\usepackage[utf8]{inputenc}
\usepackage{default}
\usepackage{hyperref}
\usepackage{textpos}
\usepackage{verbatimbox}
\usetheme{Copenhagen}

\title{Deep Learning}
\subtitle{WaveNet: From article to TensorFlow code}
\author{Tero Keski-Valkama}
\institute{\includegraphics[height=1.4cm]{CybercomG_logo_Classic_RGB.png}}
\date{2017-01-19}

\addtobeamertemplate{frametitle}{}{%
\begin{textblock*}{100mm}(10.95cm,-0.8cm)
\includegraphics[height=0.8cm]{cybercom-blue.png}
\end{textblock*}}


\begin{document}

\frame{\titlepage}
 
\begin{frame}
\frametitle{What is WaveNet}

\begin{itemize}
 \item WaveNet is a convolutional neural network architecture that aims to maximize the receptive field size for time-shift-invariant input signals.
 \item The first application for the architecture was about high sample rate audio signals with a goal of synthesizing speech.
 \item WaveNet: A Generative Model for Raw Audio by Aaron van den Oord et al. @ DeepMind: \href{https://arxiv.org/pdf/1609.03499.pdf}{https://arxiv.org/pdf/1609.03499.pdf}
 \item WaveNet Tensorflow implementation by Igor Babuschkin et al: \href{https://github.com/ibab/tensorflow-wavenet}{https://github.com/ibab/tensorflow-wavenet}
 \item The line numbers referenced refer to the repository status in 2017-01-18.
\end{itemize}

\end{frame}

\begin{frame}[fragile]
\frametitle{Causal layer}
\begin{columns}
\begin{column}{0.5\textwidth}
 
\includegraphics[width=0.9\textwidth]{./dl3_images/causal_layer.png}

\end{column}
\begin{column}{0.5\textwidth}
 
 \href{https://github.com/ibab/tensorflow-wavenet/blob/master/wavenet/model.py\#L137}{\textcolor{blue}{wavenet/model.py\#L137}}
 
 \begin{verbnobox}[\tiny]
with tf.variable_scope('causal_layer'):
        #... SCALAR INPUT STUFF ...
        #... HARD TO READ STUFF COMING DOWN TO (modified for readability): ...
    layer['filter'] = create_variable(
        'filter',
        [self.filter_width,
         self.quantization_channels,
         self.residual_channels])
 \end{verbnobox}
 
 \href{https://github.com/ibab/tensorflow-wavenet/blob/master/wavenet/model.py\#L223}{\textcolor{blue}{wavenet/model.py\#L223}}
 
 \begin{verbnobox}[\tiny]
def _create_causal_layer(self, input_batch):
    '''Creates a single causal convolution layer.
    The layer can change the number of channels.
    '''
    with tf.name_scope('causal_layer'):
        weights_filter = self.variables['causal_layer']['filter']
    return causal_conv(input_batch, weights_filter, 1)
 \end{verbnobox}
\end{column}
\end{columns} 
 
\end{frame}

\begin{frame}[fragile]
\frametitle{Causal convolution}
\begin{columns}
\begin{column}{0.5\textwidth}
 
\includegraphics[width=0.9\textwidth]{./dl3_images/causal_convolutions.png}

\includegraphics[width=0.9\textwidth]{./dl3_images/dilated_causal_convolutions.png}

\end{column}
\begin{column}{0.5\textwidth}
 
 \href{https://github.com/ibab/tensorflow-wavenet/blob/master/wavenet/ops.py\#L27}{\textcolor{blue}{wavenet/ops.py\#L27}}
 
 \begin{verbnobox}[\tiny]
def time_to_batch(value, dilation, name=None):
    with tf.name_scope('time_to_batch'):
        shape = tf.shape(value)
        pad_elements = dilation - 1 - (shape[1] + dilation - 1) % dilation
        padded = tf.pad(value, [[0, 0], [0, pad_elements], [0, 0]])
        reshaped = tf.reshape(padded, [-1, dilation, shape[2]])
        transposed = tf.transpose(reshaped, perm=[1, 0, 2])
        return tf.reshape(transposed, [shape[0] * dilation, -1, shape[2]])

def batch_to_time(value, dilation, name=None):
    with tf.name_scope('batch_to_time'):
        shape = tf.shape(value)
        prepared = tf.reshape(value, [dilation, -1, shape[2]])
        transposed = tf.transpose(prepared, perm=[1, 0, 2])
        return tf.reshape(transposed,
                          [tf.div(shape[0], dilation), -1, shape[2]])

def causal_conv(value, filter_, dilation, name='causal_conv'):
    with tf.name_scope(name):
        # Pad beforehand to preserve causality.
        filter_width = tf.shape(filter_)[0]
        padding = [[0, 0], [(filter_width - 1) * dilation, 0], [0, 0]]
        padded = tf.pad(value, padding)
        if dilation > 1:
            transformed = time_to_batch(padded, dilation)
            conv = tf.nn.conv1d(transformed, filter_, stride=1, padding='SAME')
            restored = batch_to_time(conv, dilation)
        else:
            restored = tf.nn.conv1d(padded, filter_, stride=1, padding='SAME')
        # Remove excess elements at the end.
        result = tf.slice(restored,
                          [0, 0, 0],
                          [-1, tf.shape(value)[1], -1])
    return result
 \end{verbnobox}
\end{column}
\end{columns} 
 
\end{frame}

\begin{frame}[fragile]
\frametitle{Stack of convolutional layers}
\begin{columns}
\begin{column}{0.5\textwidth}
 
\includegraphics[width=0.9\textwidth]{./dl3_images/stack_of_convolutional_layers.png}

\end{column}
\begin{column}{0.5\textwidth}
 
 \href{https://github.com/ibab/tensorflow-wavenet/blob/master/wavenet/model.py\#L390}{\textcolor{blue}{wavenet/model.py\#L390}}
 
 \begin{verbnobox}[\tiny]
  # Add all defined dilation layers.
  with tf.name_scope('dilated_stack'):
      for layer_index, dilation in enumerate(self.dilations):
          with tf.name_scope('layer{}'.format(layer_index)):
              output, current_layer = self._create_dilation_layer(
                  current_layer, layer_index, dilation)
              outputs.append(output)
 \end{verbnobox}
\end{column}
\end{columns} 
 
\end{frame}

\begin{frame}[fragile]
\frametitle{Convolutional dilation layer}
\begin{columns}
\begin{column}{0.5\textwidth}
 
\includegraphics[width=0.9\textwidth]{./dl3_images/dilation_layer.png}

\end{column}
\begin{column}{0.5\textwidth}
 \href{https://github.com/ibab/tensorflow-wavenet/blob/master/wavenet/model.py\#L232}{\textcolor{blue}{wavenet/model.py\#L232}}
 
 \begin{verbnobox}[\tiny]
def _create_dilation_layer(self, input_batch, layer_index, dilation):
        '''Creates a single causal dilated convolution layer.
        The layer contains a gated filter that connects to dense output
        and to a skip connection:
               |-> [gate]   -|        |-> 1x1 conv -> skip output
               |             |-> (*) -|
        input -|-> [filter] -|        |-> 1x1 conv -|
               |                                    |-> (+) -> dense output
               |------------------------------------|
        Where `[gate]` and `[filter]` are causal convolutions with a
        non-linear activation at the output.
        '''
        variables = self.variables['dilated_stack'][layer_index]

        weights_filter = variables['filter']
        weights_gate = variables['gate']

        conv_filter = causal_conv(input_batch, weights_filter, dilation)
        conv_gate = causal_conv(input_batch, weights_gate, dilation)

            #... CODE FOR OPTIONAL BIASES ...

        out = tf.tanh(conv_filter) * tf.sigmoid(conv_gate)

        # The 1x1 conv to produce the residual output
        weights_dense = variables['dense']
        transformed = tf.nn.conv1d(
            out, weights_dense, stride=1, padding="SAME", name="dense")

        # The 1x1 conv to produce the skip output
        weights_skip = variables['skip']
        skip_contribution = tf.nn.conv1d(
            out, weights_skip, stride=1, padding="SAME", name="skip")

            #... CODE FOR OPTIONAL BIASES / HISTOGRAM OUTPUT ...
        
        return skip_contribution, input_batch + transformed
 \end{verbnobox}

\end{column}
\end{columns} 
 
\end{frame}

\begin{frame}[fragile]
\frametitle{1X1 Convolutions (dilation layer)}
\begin{columns}
\begin{column}{0.5\textwidth}
 
\includegraphics[width=0.9\textwidth]{./dl3_images/1x1_convolutions_1.png}

\end{column}
\begin{column}{0.5\textwidth}
{\tiny
\begin{itemize}
 \item It is important to follow the channel number per ``pixel`` in every part of the diagram. Channel number can be intuitively thought as a color component number for graphical
signals, or number of per-pixel features for audio signals. All the convolutions potentially change the channel number.
 \item 1x1 convolutions are needed to convert the numbers of channels from one part of the diagram to another. They are single pixel, context independent fully-connected matrices mapping
n-dimensional pixel to m-dimensional pixel with learnable weights.
 \item Note that all other operations except convolutions work for each channel independently and do not affect the numbers of channels.
 \item The only channel number mentioned in the original paper is the number of $ \mu $-law quantization channels (256), the other parameters are left open.
The ibab implementation assumes that the number of channels in the second to final 1x1 convolution does not change, and stays the same (skip\_channels=512). This does not have to be so.
\end{itemize}
}
\end{column}
\end{columns} 
 
\end{frame}

\begin{frame}[fragile]
\frametitle{1X1 Convolutions (dilation layer)}
\begin{columns}
\begin{column}{0.5\textwidth}
 
\includegraphics[width=0.9\textwidth]{./dl3_images/1x1_convolutions_2.png}

\end{column}
\begin{column}{0.5\textwidth}
 
\href{https://github.com/ibab/tensorflow-wavenet/blob/master/wavenet/model.py\#L167}{\textcolor{blue}{wavenet/model.py\#L167}}
 
\begin{verbnobox}[\tiny]
    current['dense'] = create_variable(
        'dense',
        [1,
            self.dilation_channels,
            self.residual_channels])
    current['skip'] = create_variable(
        'skip',
        [1,
            self.dilation_channels,
            self.skip_channels])
\end{verbnobox}

\href{https://github.com/ibab/tensorflow-wavenet/blob/master/wavenet/model.py\#L290}{\textcolor{blue}{wavenet/model.py\#L290}}
 
 \begin{verbnobox}[\tiny]
    # The 1x1 conv to produce the residual output
    weights_dense = variables['dense']
    transformed = tf.nn.conv1d(
        out, weights_dense, stride=1, padding="SAME", name="dense")

    # The 1x1 conv to produce the skip output
    weights_skip = variables['skip']
    skip_contribution = tf.nn.conv1d(
        out, weights_skip, stride=1, padding="SAME", name="skip")
\end{verbnobox}

\end{column}
\end{columns} 
 
\end{frame}

\begin{frame}[fragile]
\frametitle{1X1 Convolutions (postprocessing)}
\begin{columns}
\begin{column}{0.5\textwidth}
 
\includegraphics[width=0.9\textwidth]{./dl3_images/1x1_convolutions_3.png}

\end{column}
\begin{column}{0.5\textwidth}
 
 \href{https://github.com/ibab/tensorflow-wavenet/blob/master/wavenet/model.py\#L206}{\textcolor{blue}{wavenet/model.py\#L206}}
 
\begin{verbnobox}[\tiny]
    current['postprocess1'] = create_variable(
        'postprocess1',
        [1, self.skip_channels, self.skip_channels])
    current['postprocess2'] = create_variable(
        'postprocess2',
        [1, self.skip_channels, self.quantization_channels])
\end{verbnobox}

 \href{https://github.com/ibab/tensorflow-wavenet/blob/master/wavenet/model.py\#L402}{\textcolor{blue}{wavenet/model.py\#L402}}
 
 \begin{verbnobox}[\tiny]
    w1 = self.variables['postprocessing']['postprocess1']
    w2 = self.variables['postprocessing']['postprocess2']
        #... CODE FOR OPTIONAL BIASES / HISTOGRAM OUTPUT ...
    # We skip connections from the outputs of each layer, adding them
    # all up here.
    total = sum(outputs)
    transformed1 = tf.nn.relu(total)
    conv1 = tf.nn.conv1d(transformed1, w1, stride=1, padding="SAME")
        #... CODE FOR OPTIONAL BIASES ...
    transformed2 = tf.nn.relu(conv1)
    conv2 = tf.nn.conv1d(transformed2, w2, stride=1, padding="SAME")
\end{verbnobox}

\end{column}
\end{columns} 
 
\end{frame}

\end{document}

